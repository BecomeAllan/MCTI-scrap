{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BecomeAllan/MCTI-scrap/blob/main/MCTI_SCRAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EWhPSC2v3F"
      },
      "source": [
        "# Scrap functions\n",
        "\n",
        "Main call para buscar informações dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TaZ_OQJfyKIZ"
      },
      "outputs": [],
      "source": [
        "from Functions.royal import *\n",
        "from Functions.thegef import *\n",
        "from Functions.iadb import *\n",
        "from Functions.ICGEB import *\n",
        "from Functions.speciesconservation import *\n",
        "from Functions.ramsar import *\n",
        "from Functions.globalwomennet import *\n",
        "from Functions.arcadia import *\n",
        "from Functions.ruffordj import *\n",
        "\n",
        "funs = [\n",
        "        royal1,\n",
        "        royal2,\n",
        "        royal3,\n",
        "        thegef2,\n",
        "        thegef3,\n",
        "        iadb4,\n",
        "        icgeb1,\n",
        "        icgeb2,\n",
        "        icgeb3,\n",
        "        speciesconservation1,\n",
        "        speciesconservation2,\n",
        "        speciesconservation3,\n",
        "        speciesconservation4,\n",
        "        ramsar2,\n",
        "        ramsar3,\n",
        "        globalwomennet1,\n",
        "        # globalwomennet2,\n",
        "        globalwomennet3,\n",
        "        arcadia2,\n",
        "        arcadia3,\n",
        "        # arcadia4,\n",
        "        rufford1,\n",
        "        rufford2,\n",
        "        rufford3,\n",
        "        rufford4\n",
        "        ]\n",
        "\n",
        "\n",
        "def call_fun(fun, *args, **keyargs):\n",
        "  return fun(*args, **keyargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxZ9B7Py5Pd3"
      },
      "source": [
        "# PPFcentral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_I2XEyh4voj",
        "outputId": "896a1cc3-0960-46e0-a8a7-b293506bb246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diretório já existente\n",
            "Diretório já existente\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import filecmp \n",
        "from filecmp import dircmp\n",
        "import os\n",
        "from os import walk\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import shutil\n",
        "from itertools import compress\n",
        "from multiprocessing import Pool, freeze_support\n",
        "from itertools import repeat\n",
        "from functools import partial\n",
        "# Definindo o diretório para salvar os arquivos\n",
        "# os.chdir(r'D:\\Users\\beatriz.simoes\\Desktop\\codigos\\mcti-sefip-ppfcd2020\\output')\n",
        "#-------------------------- Criação das pastas -------------------\n",
        "# PASTA DIARIA\n",
        "dia = datetime.today().strftime('%y%m%d') # yy/mm/dd\n",
        "if os.path.exists(dia):\n",
        " print('Diretório já existente')   #nada acontece\n",
        "else:\n",
        "    os.makedirs(dia) #cria o diretório \n",
        "    print('Diretório criado')\n",
        "# PASTA PRINCIPAL\n",
        "baseprincipal = './/baseprincipal'\n",
        "if os.path.exists(baseprincipal):\n",
        " print('Diretório já existente')   #nada acontece\n",
        "else:\n",
        "    os.makedirs(baseprincipal) #cria o diretório \n",
        "    print('Diretório criado')\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#-------------------- SCRAPING PARA PASTA DIÁRIA:  -------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "#  (aqui ficarão as importações dos arquivos py para scraping diário)\n",
        "\n",
        "try:\n",
        "  with Pool(2) as pool:\n",
        "    pool.map(partial(call_fun, path='.//' + dia), funs)\n",
        "except:\n",
        "    print('Erro na extração, verificar arquivo fonte')\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#--------------------------------- Funções  -----------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "#-----------\n",
        "# ---- função que define o caminho da pasta------------------\n",
        "def paths(pasta,arquivo):\n",
        "    path = '''.\\\\'''+pasta+'''\\\\'''+arquivo\n",
        "    return(path)\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "# --------------------------- função que atualiza a base --------------\n",
        "def atualizador(baseprincipal,diamaisrecente):\n",
        "    diario = pd.read_csv(diamaisrecente)\n",
        "    main = pd.read_csv(baseprincipal)\n",
        "    # checando o que do 'diario' está no 'main'\n",
        "    a = diario['link'].isin(main['link'])   # usar o tag/id criado inves do link\n",
        "    b = [not bool for bool in a] # inverter para o TRUE ser a linha que não tem no main\n",
        "    novaslinhas = diario[b]\n",
        "    main = main.append(novaslinhas,ignore_index=True) #novo main\n",
        "    main.to_csv(baseprincipal,index=False,sep=\",\")\n",
        "    print('A base foi atualizada')\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#--------------------------------- Comparação  -----------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "\n",
        "#------------   pegando todos os diretórios da pasta output\n",
        "\n",
        "_,dirnames,_  = next(walk('.'))\n",
        "dirnames.sort(reverse=True) # Os obj 0 vai ser a base principal. o 1 vai ser o dia mais recente e o 2 o dia anterior.\n",
        "\n",
        "_,_,filenamesDia = next(walk('.//'+dia)) # Arquivos extraídos no dia.\n",
        "_,_,filenamesBase = next(walk('.//baseprincipal')) # Arquivos extraídos na base.\n",
        "\n",
        "# # -------------------------------- Se o arquivo não tiver na base:\n",
        "# # Verificando se os nomes que estão no Dia estão na Base.\n",
        "a = [i in filenamesBase for i in  filenamesDia]\n",
        "a = [not bool for bool in a] # inversão pro True ser o arquivo faltante\n",
        "arquivos = list(compress(filenamesDia, a)) # arquivo que está faltando na baseprincipal\n",
        "for f in arquivos:\n",
        "    shutil.copy('.//'+dia+'//'+f, './/baseprincipal')\n",
        "# # ------------------------------------------------------\n",
        "\n",
        "\n",
        "# #---------------------------------------------------------------------------\n",
        "# #--------------------------------- Atualização  ----------------------------\n",
        "# #---------------------------------------------------------------------------\n",
        "filenames = filenamesDia\n",
        "\n",
        "for i in range(0,len(filenames)):\n",
        "    try:\n",
        "        base = str(paths(dirnames[0],filenames[i])) #base \n",
        "        dia1 = paths(dirnames[1],filenames[i]) #dia mais recente \n",
        "        dia2 = paths(dirnames[2],filenames[i]) #dia anterior \n",
        "        comp = filecmp.cmp(dia1, dia2, shallow = False)\n",
        "        if comp==False:\n",
        "            print('arquivos diários são diferentes, base atualizada')\n",
        "            atualizador(base,dia1)\n",
        "        else:\n",
        "            print('arquivos diários são iguais, base não atualizada')\n",
        "    except:\n",
        "      print(\"Arquivo do dia anterior não encontrado\")\n",
        "\n",
        "    print('Concluido arquivo '+str(i+1))\n",
        "\n",
        "# como a coluna codigo contem o dia, os arquivos sempre vão ser diferentes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOzRfJx5ZvAkffO/0VDnZd/",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "MCTI-SCRAP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
