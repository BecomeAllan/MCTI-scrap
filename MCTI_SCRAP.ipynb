{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BecomeAllan/MCTI-scrap/blob/main/MCTI_SCRAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EWhPSC2v3F"
      },
      "source": [
        "# Scrap functions\n",
        "\n",
        "Main call para buscar informações dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TaZ_OQJfyKIZ"
      },
      "outputs": [],
      "source": [
        "from Functions.royal import *\n",
        "from Functions.thegef import *\n",
        "from Functions.iadb import *\n",
        "from Functions.ICGEB import *\n",
        "from Functions.speciesconservation import *\n",
        "from Functions.ramsar import *\n",
        "from Functions.globalwomennet import *\n",
        "from Functions.arcadia import *\n",
        "from Functions.ruffordj import *\n",
        "\n",
        "# from royal import *\n",
        "# from thegef import *\n",
        "# from iadb import *\n",
        "# from ICGEB import *\n",
        "# from speciesconservation import *\n",
        "# from ramsar import *\n",
        "# from globalwomennet import *\n",
        "# from arcadia import *\n",
        "# from ruffordj import *\n",
        "\n",
        "funs = [\n",
        "        royal1,\n",
        "        royal2,\n",
        "        royal3,\n",
        "        thegef2,\n",
        "        thegef3,\n",
        "        iadb4,\n",
        "        icgeb1,\n",
        "        icgeb2,\n",
        "        icgeb3,\n",
        "        speciesconservation1,\n",
        "        speciesconservation2,\n",
        "        speciesconservation3,\n",
        "        speciesconservation4,\n",
        "        ramsar2,\n",
        "        ramsar3,\n",
        "        globalwomennet1,\n",
        "        # globalwomennet2,\n",
        "        globalwomennet3,\n",
        "        arcadia2,\n",
        "        arcadia3,\n",
        "        # arcadia4,\n",
        "        rufford1,\n",
        "        rufford2,\n",
        "        rufford3,\n",
        "        rufford4\n",
        "        ]\n",
        "\n",
        "\n",
        "def call_fun(fun, *args, **keyargs):\n",
        "  return fun(*args, **keyargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxZ9B7Py5Pd3"
      },
      "source": [
        "# PPFcentral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_I2XEyh4voj",
        "outputId": "e6652aa9-46cc-4c77-a58f-621a280e0459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório criado\n",
            "Diretório criado\n",
            "[thegef][noticias][start]\n",
            "[royal][oportunidades][start]\n",
            "[thegef][noticias][end]\n",
            "[thegef][politicas][start]\n",
            "[thegef][politicas][end]\n",
            "[iadb4][projetos][start]\n",
            "[iadb4][projetos][end]\n",
            "[icgeb][oportunidades][start]\n",
            "[icgeb][oportunidades][end]\n",
            "[icgeb][noticias][start]\n",
            "[royal][oportunidades][end]\n",
            "[royal][noticias][start]\n",
            "[icgeb][noticias][end]\n",
            "[icgeb][politicas][start]\n",
            "[icgeb][politicas][start]\n",
            "[speciesconservation][oportunidades][start]\n",
            "None\n",
            "[speciesconservation][oportunidades][end]\n",
            "[speciesconservation][noticias][start]\n",
            "[royal][oportunidades][end]\n",
            "[royal][politicas][start]\n",
            "[speciesconservation][noticias][end]\n",
            "[speciesconservation][politicas][start]\n",
            "[royal][politicas][end]\n",
            "[speciesconservation][oportunidades][start]\n",
            "[speciesconservation][politicas][end]\n",
            "[globalwomennet][oportunidades][start]\n",
            "[speciesconservation][oportunidades][end]\n",
            "[ramsar][noticias][start]\n",
            "[globalwomennet][oportunidades][start]\n",
            "[globalwomennet][noticias][start]\n",
            "[globalwomennet][noticias][end]\n",
            "[arcadia][arcadia2][start]\n",
            "[arcadia][arcadia2][end]\n",
            "[arcadia][arcadia3][start]\n",
            "[arcadia][arcadia3][end]\n",
            "[rufford][rufford1][start]\n",
            "[rufford][rufford1][end]\n",
            "[rufford][rufford2][start]\n",
            "[rufford][rufford2][end]\n",
            "[rufford][rufford3][start]\n",
            "[rufford][rufford3][end]\n",
            "[rufford][rufford4][start]\n",
            "Função encerrada\n",
            "[rufford][rufford4][end]\n",
            "[ramsar][politicas][end]\n",
            "[ramsar][politicas][start]\n",
            "[ramsar][politicas][end]\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 1\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 2\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 3\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 4\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 5\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 6\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 7\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 8\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 9\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 10\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 11\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 12\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 13\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 14\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 15\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 16\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 17\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 18\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 19\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 20\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 21\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 22\n",
            "Arquivo do dia anterior não encontrado\n",
            "Concluido arquivo 23\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import filecmp \n",
        "from filecmp import dircmp\n",
        "import os\n",
        "from os import walk\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import shutil\n",
        "from itertools import compress\n",
        "from multiprocessing import Pool, freeze_support\n",
        "from itertools import repeat\n",
        "from functools import partial\n",
        "# Definindo o diretório para salvar os arquivos\n",
        "# os.chdir(r'D:\\Users\\beatriz.simoes\\Desktop\\codigos\\mcti-sefip-ppfcd2020\\output')\n",
        "#-------------------------- Criação das pastas -------------------\n",
        "# PASTA DIARIA\n",
        "dia = datetime.today().strftime('%y%m%d') # yy/mm/dd\n",
        "if os.path.exists(dia):\n",
        " print('Diretório já existente')   #nada acontece\n",
        "else:\n",
        "    os.makedirs(dia) #cria o diretório \n",
        "    print('Diretório criado')\n",
        "# PASTA PRINCIPAL\n",
        "baseprincipal = './/baseprincipal'\n",
        "if os.path.exists(baseprincipal):\n",
        " print('Diretório já existente')   #nada acontece\n",
        "else:\n",
        "    os.makedirs(baseprincipal) #cria o diretório \n",
        "    print('Diretório criado')\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#-------------------- SCRAPING PARA PASTA DIÁRIA:  -------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "#  (aqui ficarão as importações dos arquivos py para scraping diário)\n",
        "\n",
        "try:\n",
        "  with Pool(2) as pool:\n",
        "    pool.map(partial(call_fun, path='.//' + dia), funs)\n",
        "except:\n",
        "    print('Erro na extração, verificar arquivo fonte')\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#--------------------------------- Funções  -----------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "#-----------\n",
        "# ---- função que define o caminho da pasta------------------\n",
        "def paths(pasta,arquivo):\n",
        "    path = '''.\\\\'''+pasta+'''\\\\'''+arquivo\n",
        "    return(path)\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "# --------------------------- função que atualiza a base --------------\n",
        "def atualizador(baseprincipal,diamaisrecente):\n",
        "    diario = pd.read_csv(diamaisrecente)\n",
        "    main = pd.read_csv(baseprincipal)\n",
        "    # checando o que do 'diario' está no 'main'\n",
        "    a = diario['link'].isin(main['link'])   # usar o tag/id criado inves do link\n",
        "    b = [not bool for bool in a] # inverter para o TRUE ser a linha que não tem no main\n",
        "    novaslinhas = diario[b]\n",
        "    main = main.append(novaslinhas,ignore_index=True) #novo main\n",
        "    main.to_csv(baseprincipal,index=False,sep=\",\")\n",
        "    print('A base foi atualizada')\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#--------------------------------- Comparação  -----------------------------\n",
        "#---------------------------------------------------------------------------\n",
        "\n",
        "#------------   pegando todos os diretórios da pasta output\n",
        "\n",
        "_,dirnames,_  = next(walk('.'))\n",
        "dirnames.sort(reverse=True) # Os obj 0 vai ser a base principal. o 1 vai ser o dia mais recente e o 2 o dia anterior.\n",
        "\n",
        "_,_,filenamesDia = next(walk('.//'+dia)) # Arquivos extraídos no dia.\n",
        "_,_,filenamesBase = next(walk('.//baseprincipal')) # Arquivos extraídos na base.\n",
        "\n",
        "# # -------------------------------- Se o arquivo não tiver na base:\n",
        "# # Verificando se os nomes que estão no Dia estão na Base.\n",
        "a = [i in filenamesBase for i in  filenamesDia]\n",
        "a = [not bool for bool in a] # inversão pro True ser o arquivo faltante\n",
        "arquivos = list(compress(filenamesDia, a)) # arquivo que está faltando na baseprincipal\n",
        "for f in arquivos:\n",
        "    shutil.copy('.//'+dia+'//'+f, './/baseprincipal')\n",
        "# # ------------------------------------------------------\n",
        "\n",
        "\n",
        "# #---------------------------------------------------------------------------\n",
        "# #--------------------------------- Atualização  ----------------------------\n",
        "# #---------------------------------------------------------------------------\n",
        "filenames = filenamesDia\n",
        "\n",
        "for i in range(0,len(filenames)):\n",
        "    try:\n",
        "        base = str(paths(dirnames[0],filenames[i])) #base \n",
        "        dia1 = paths(dirnames[1],filenames[i]) #dia mais recente \n",
        "        dia2 = paths(dirnames[2],filenames[i]) #dia anterior \n",
        "        comp = filecmp.cmp(dia1, dia2, shallow = False)\n",
        "        if comp==False:\n",
        "            print('arquivos diários são diferentes, base atualizada')\n",
        "            atualizador(base,dia1)\n",
        "        else:\n",
        "            print('arquivos diários são iguais, base não atualizada')\n",
        "    except:\n",
        "      print(\"Arquivo do dia anterior não encontrado\")\n",
        "\n",
        "    print('Concluido arquivo '+str(i+1))\n",
        "\n",
        "# como a coluna codigo contem o dia, os arquivos sempre vão ser diferentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/220211.zip /content/220211"
      ],
      "metadata": {
        "id": "G5ffujGkW8oY",
        "outputId": "1a50b5ce-91c1-4745-a61d-60604b8aeae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/220211/ (stored 0%)\n",
            "  adding: content/220211/ramsar_02.csv (deflated 76%)\n",
            "  adding: content/220211/speciesconservation_03.csv (deflated 59%)\n",
            "  adding: content/220211/speciesconservation_04.csv (deflated 74%)\n",
            "  adding: content/220211/icgeb_03.csv (deflated 57%)\n",
            "  adding: content/220211/royalsociety_02.csv (deflated 63%)\n",
            "  adding: content/220211/arcadia_03.csv (deflated 43%)\n",
            "  adding: content/220211/icgeb_01.csv (deflated 77%)\n",
            "  adding: content/220211/thegef_03.csv (deflated 69%)\n",
            "  adding: content/220211/icgeb_02.csv (deflated 61%)\n",
            "  adding: content/220211/globalwomennet_03.csv (deflated 57%)\n",
            "  adding: content/220211/speciesconservation_02.csv (deflated 65%)\n",
            "  adding: content/220211/iadb_12.csv (deflated 69%)\n",
            "  adding: content/220211/rufford_01.csv (deflated 78%)\n",
            "  adding: content/220211/royalsociety_01.csv (deflated 87%)\n",
            "  adding: content/220211/thegef_02.csv (deflated 58%)\n",
            "  adding: content/220211/speciesconservation_01.csv (deflated 76%)\n",
            "  adding: content/220211/rufford_10.csv (deflated 63%)\n",
            "  adding: content/220211/rufford_03.csv (deflated 44%)\n",
            "  adding: content/220211/globalwomennet_01.csv (deflated 57%)\n",
            "  adding: content/220211/rufford_02.csv (deflated 60%)\n",
            "  adding: content/220211/royalsociety_03.csv (deflated 60%)\n",
            "  adding: content/220211/arcadia_02.csv (deflated 69%)\n",
            "  adding: content/220211/ramsar_03.csv (deflated 60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/baseprincipal.zip /content/baseprincipal"
      ],
      "metadata": {
        "id": "6hbJKvkLXFub",
        "outputId": "e1f64722-fa7d-461f-8efe-3bbc66aa5d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/baseprincipal/ (stored 0%)\n",
            "  adding: content/baseprincipal/ramsar_02.csv (deflated 76%)\n",
            "  adding: content/baseprincipal/speciesconservation_03.csv (deflated 59%)\n",
            "  adding: content/baseprincipal/speciesconservation_04.csv (deflated 74%)\n",
            "  adding: content/baseprincipal/icgeb_03.csv (deflated 57%)\n",
            "  adding: content/baseprincipal/royalsociety_02.csv (deflated 63%)\n",
            "  adding: content/baseprincipal/arcadia_03.csv (deflated 43%)\n",
            "  adding: content/baseprincipal/icgeb_01.csv (deflated 77%)\n",
            "  adding: content/baseprincipal/thegef_03.csv (deflated 69%)\n",
            "  adding: content/baseprincipal/icgeb_02.csv (deflated 61%)\n",
            "  adding: content/baseprincipal/globalwomennet_03.csv (deflated 57%)\n",
            "  adding: content/baseprincipal/speciesconservation_02.csv (deflated 65%)\n",
            "  adding: content/baseprincipal/iadb_12.csv (deflated 69%)\n",
            "  adding: content/baseprincipal/rufford_01.csv (deflated 78%)\n",
            "  adding: content/baseprincipal/royalsociety_01.csv (deflated 87%)\n",
            "  adding: content/baseprincipal/thegef_02.csv (deflated 58%)\n",
            "  adding: content/baseprincipal/speciesconservation_01.csv (deflated 76%)\n",
            "  adding: content/baseprincipal/rufford_10.csv (deflated 63%)\n",
            "  adding: content/baseprincipal/rufford_03.csv (deflated 44%)\n",
            "  adding: content/baseprincipal/globalwomennet_01.csv (deflated 57%)\n",
            "  adding: content/baseprincipal/rufford_02.csv (deflated 60%)\n",
            "  adding: content/baseprincipal/royalsociety_03.csv (deflated 60%)\n",
            "  adding: content/baseprincipal/arcadia_02.csv (deflated 69%)\n",
            "  adding: content/baseprincipal/ramsar_03.csv (deflated 60%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MCTI-SCRAP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}